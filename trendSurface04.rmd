---
title: "Trend Surface Analysis with R (part IV)"
output: html_notebook
---
##-- arkriger: August 2023

We end our journey through *higher order* **_Trend Surface analysis with R_** with this Notebook. Here we cover a lot of ground:

1. Generalized Least Squares (GLS)
	a) Variogram Modeling and
	b) Ordinary Kriging
2. GLS-Regression Kriging
3. Universal Kriging

$\color{red}{\text{\textbf{REQUIRED}}}$: 
**You are required to insert your outputs and any comment into this document.** The document you submit should therefore contain the existing text in addition to:

- Plots and other outputs from executing the code chunks
- Discussion of your plots and other outputs as well as conclusions reached.
- This should also include any hypotheses and assumptions made as well as factors that may affect your conclusions.

At the close of the previous Notebook we talked about **_spatial autocorrelation_**. Patterns and particularly residuals (errors) have a spatial structure / are connected.

What we mean by this is; that even though an estimate _(prediction)_ is unbiased the **structure of the underlying data can be**. A general error term applied to our entire study area might not be ideal.

To overcome the challenge; we use Generalized Least Squares and introduce a **covariance structure between residuals**. Our `linear model`, from [trendSurface02](https://github.com/AdrianKriger/r-trend-surfaces/blob/main/trendSurface02.rmd) then becomes:

$$
    𝜷_{gls} = (X^TC^{-1}X)^{-1}X^TC^{-1} . y
$$

We see our new term includes $C$; the covariance matrix of the spatially correlated residuals.

The obvious question is. _'OK; so what are the correlated residuals?'_
And the answer is: _'We dont know'_.

What we do is fit the covariance structure (based on imprecise observations) at the same time we calculate the trend surface coefficients.

```{r install }
options(prompt="> ", continue="+ ", digits=3, width=70,  show.signif.stars=F, repr.plot.width=7, repr.plot.height=7)
rm(list=ls())

# Install necessary packages: You only need to run this part once
##- install.packages(c("sf", "gstat", "ggplot2", "gridExtra","units", "terra","mgcv","fields", "nlme"))

#library(repr)
library(sf) # 'simple features' representations of spatial objects
library(gstat) # geostatistics
library(ggplot2) # geostatistics
library(gridExtra)
library(units) # units of measure
library(terra) # gridded data structures ("rasters")
library(mgcv)
library(fields)
library(nlme)
```

We've already covered creating a 500m grid and 2nd-order prediction and interpolation with previous Notebooks and move through the introduction quickly.

```{r read-dataset }
#-- read
file = 'cptFlatsAquifer_watertable4.txt'
```

```{r import-grid-2nd-ols-gam }
#-- import
cfaq <- read.csv(file, header = 1, sep = ',', dec = '.') #sep = '\t',
#- set crs
cfaq.sf <- st_as_sf(cfaq, coords=c("long", "lat"), crs = 4326) #wgs84
#- transform to local crs
cfaq.sf <- st_transform(cfaq.sf, crs = 32734) #utm 34s
cfaq$X <- st_coordinates(cfaq.sf)[, "X"]
cfaq$Y <- st_coordinates(cfaq.sf)[, "Y"]

model.ts2 <- lm(waterLevel ~ X + Y + I(X^2) + I(Y^2) + I(X*Y), data=drop_units(cfaq))

#--  create grid
(n.col <- length(seq.e <- seq(min.x <- floor(min(cfaq$X)/1000)*1000,
                              max.x <- ceiling(max(cfaq$X)/1000)*1000, by=1000)))
(n.row <- length(seq.n <- seq(min.y <- floor(min(cfaq$Y)/1000)*1000,
                              max.y <- ceiling(max(cfaq$Y)/1000)*1000, by=1000)))

#we want a XXXXm grid
grid <- rast(nrows = n.row, ncols = n.col,
             xmin=min.x, xmax=max.x,
             ymin=min.y, ymax=max.y, crs = st_crs(cfaq.sf)$proj4string,
             resolution = 500, names="waterLevel")

values(grid) <- NA_real_

grid.df <- as.data.frame(grid, xy = TRUE, na.rm = FALSE)
names(grid.df)[1:2] <- c("X", "Y") # match the names of the point dataset
summary(grid.df)

#--
pred.ts2 <- predict.lm(model.ts2,
                       newdata = grid.df,
                       interval = "prediction", level = 0.95)

#-- add the three prediction fields (fit, lower, upper) to the data
grid.df[, 3:5] <- pred.ts2
names(grid.df)[3:5] <- c("ts2.fit", "ts2.lwr", "ts2.upr")

#-- gam
model.gam <- gam(waterLevel ~ s(X, Y, k = 29), data=drop_units(cfaq))
#-- predict aquifer elevation, standard error of prediction using the fitted GAM
tmp <- predict.gam(object=model.gam,
                   newdata=grid.df,
                   se.fit=TRUE)

grid.df$pred.gam <- as.numeric(tmp$fit)
grid.df$pred.gam.se <- as.numeric(tmp$se.fit)

grid.gam <- grid
values(grid.gam) <- grid.df$pred.gam
```

```{r look }
#-- look
head(cfaq ,3)
```

To compute the trend and covariance at the same time we use the `gls` function in the the `nlme` package.

```{r gls-model-class }
#- gls with coefficient
model.ts2.gls <- gls(
  model = waterLevel ~ Y + X + I(Y^2) + I(X^2) + I(X * Y),
  data = drop_units(cfaq),
  method = "ML",
  correlation = corExp(form = ~X + Y,
                       nugget = FALSE,
                       value = 10000) # initial value of the range parameter
)
#model.ts2.gls
class(model.ts2.gls)
```

```{r gls-summary }
summary(model.ts2.gls)
```

$\color{red}{\text{\textbf{QUESTION}}}$: 
- What is the range of spatial correlation of the exponential model, as estimated by GLS?

```{ r ans-01}
[click in this cell and type your answer here]
```

**Look at how the GLS and OLS coefficients differ.**

We work with the **Mixed GAM Computation Vehicle** `mgcv` library default smoothing setting and explore **thin plate splines**, as an alternate smoothing function later.

```{r summarize-gls-uncertainty }
##-- absolute values
#- generic coef method extracts coefficients from model objects
coef(model.ts2.gls) - coef(model.ts2)

```{r summarize-gls-uncertainty-percent }
#- percentage
round(100*(coef(model.ts2.gls) - coef(model.ts2))/coef(model.ts2),1)
```

$\color{red}{\text{\textbf{QUESTION}}}$: 
- Why are the GLS coefficients different than the OLS coefficients?

```{ r ans-02}
[click in this cell and type your answer here]
```

**Lets go deeper.**

Display the $90\%$ confidence intervals of the GLS model, calcualte the residuals of this surface and compare those to the OLS.

```{r gls-intervals }
#- generic intervals method has a specific method for a fitted GLS model
intervals(model.ts2.gls, level=0.90)
```

```{r 2nd-ols-summary }
summary(res.ts2)
```

$\color{red}{\text{\textbf{QUESTION}}}$: 
- What are the main differences between these sets of residuals? Which surface, in this case, most closely fits the points? Why?

```{ r ans-03}
[click in this cell and type your answer here]
```

```{r predict-gls-summary }
#- predict.gls function (of the nlme package) specific method for a fitted GLS model
pred.ts2.gls <- predict(model.ts2.gls, newdata=grid.df)
summary(pred.ts2.gls)
```

#- SpatRast of predictions
grid.gls <- grid
values(grid.gls) <- pred.ts2.gls
summary(values(grid.gls))

```{r plot-gls }
#- plot
plot(grid.gls, col = rainbow(100), main = "GLS 2nd order predicted surface")
points(st_coordinates(cfaq.sf)[,2] ~ st_coordinates(cfaq.sf)[,1],
       #pch=16,
       #col = ifelse((res.ts2.gls < 0), "red", "green"),
       #cex=2*abs(res.ts2.gls)/max(abs(res.ts2.gls))
       col= ifelse((res.ts2.gls < 0), "red", "green"),
       cex=2*abs(res.ts2.gls)/max(abs(res.ts2.gls)),
       pch=21,
       bg = adjustcolor("black", alpha.f = 0.1),
       #col = "black",
       #cex = 0.9,
       lwd = 0.5)
```

**Notice how closely this prediction resembles the OLS 2nd-order trend surface!**

Lets see how different?

$\color{red}{\text{\textbf{QUESTION}}}$: 
- What are the main differences between these sets of residuals? Which surface, in this case, most closely fits the points? Why?

```{ r ans-04}
[click in this cell and type your answer here]
```

```{r plot-diff-ols-gls }
#- difference between the OLS and GLS trendsurfaces
grid.gls.ols.diff <- (grid.gls - grid)
plot(grid.gls.ols.diff, col = topo.colors(64),
     main = "GLS - OLS 2nd order trend surfaces, m")
```

$\color{red}{\text{\textbf{QUESTION}}}$: 
- Where are the largest differences between the OLS and GLS trend surfaces? Explain why.

```{ r ans-05}
[click in this cell and type your answer here]
```

Lets look at the residuals

```{r residuals-gls-summary }
#- residuals from the GLS trend surface and as a postplot
summary(res.ts2.gls)
```
```{r gls-fit-residuals }
#- plot
plot(cfaq$Y ~ cfaq$X, cex=3*abs(res.ts2.gls)/max(abs(res.ts2.gls)),
     col=ifelse(res.ts2.gls > 0, "green", "red"),
     xlab="X", ylab="Y",
     main="Residuals from 2nd-order trend, GLS fit",
     sub="Positive: green; negative: red", asp=1)
##--  ??local spatial correlation?? --##
```

**Look at how correlated the residuals are. Nearby data points have similar values**

We now account for the spatial correlation of the residuals

```{r empirical-variogram }
#-  empirical variogram model residuals from the GLS trend surface model

#- extract the residuals into the point observations object
cfaq.sf$res.ts2.gls <- residuals(model.ts2.gls)
vr.gls <- variogram(res.ts2.gls ~ 1, loc=cfaq.sf, cutoff = 50000)
#- plot empirical variogram
plot(vr.gls, plot.numbers=T,
     main="Residuals from second-order GLS trend", cex=1,
     xlab = "separation [m]", ylab = "semivariance [m^2]")
```

$\color{red}{\text{\textbf{QUESTION}}}$: 
- What are the approximate variogram parameters?

```{ r ans-06}
[click in this cell and type your answer here]
```

###1. a) Variogram Modeling

In order to solve any Kriging formula we need to compute the semivariance at _any_ seperation distance. We want to know the values that will remove the _'overlarge influence'_ nearby datapoints have on a prediction.

In order to do so we fit a variogram function to the empirical variogram. The function represent the structure of spatial autocorrelation. There are many variogram functions: _'Exponential, Spherical, Gauss, Matern'_.  

We will not go into these here but remember to `effective-range / 3` when chooing an _'Exponential'_ model.

```{r variogram-model }
#-  specify variogram model and parameters
vr.gls.m <- vgm(psill=200, model="Mat", range=15000)#, nugget=25)
#vr.gls.m <- vgm(psill=40, model="Exp", range=22000/3, nugget=0)
(vr.gls.m.f <- fit.variogram(vr.gls, vr.gls.m)
```

```{r plot-variogram-model }
#- plot
plot(vr.gls, model=vr.gls.m.f, plot.numbers=T,
     xlab = "separation [m]", ylab = "semivariance [m^2]")
```

```{r print-model }
print(vr.gls.m.f)
```

```{r variogram-intervals }
intervals(model.ts2.gls)$corStruct[2]
```

$\color{red}{\text{\textbf{QUESTION}}}$: 
- Does the range parameter of this fitted model agree with the estimate from the GLS fit?

```{ r ans-07}
[click in this cell and type your answer here]
```

### 1. b) The Ordinary Kriging system

Kriging is a form of linear prediction of a value at an unknown point as a weighted sum of values at known points.

This makes sense. We know the structure (spatial correlation) of the residuals, their values and their location. And we use this knowledge to refine our GLS prediction.  

But what really makes Kriging special _(and computationally expensive)_ is the system ensures that each prediction has the least possible prediction variance. The _**uncertainty**_ of the predictions are minimized.